from dotenv import load_dotenv
import os
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from pprint import pprint

# Carga las variables del archivo .env
load_dotenv()

# 1. Configuraci√≥n de la API de Groq y del LLM
try:
    groq_api_key = os.environ["GROQ_API_KEY"]
except KeyError:
    print("Error: La variable de entorno 'GROQ_API_KEY' no est√° configurada.")
    print("Por favor, config√∫rala antes de ejecutar el script.")
    exit()

chat = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name="llama-3.1-8b-instant")

# 2. Creaci√≥n del "Contexto MCP" (simulaci√≥n)
mcp_context = {
    "protocol": "mcp-v1",
    "sender": "Agente_Planificador",
    "recipient": "Agente_Creativo",
    "context": {
        "conversation_id": "marketing_campaign_2025",
        "metadata": {
            "timestamp": "2025-09-19T10:00:00Z"
        },
        "payload": {
            "campaign_goal": "Aumentar el engagement en Instagram en un 20% para el pr√≥ximo trimestre.",
            "product_name": "Eco-Botellas Reusables",
            "target_audience": "J√≥venes (18-30 a√±os) con inter√©s en la sostenibilidad y el fitness.",
            "key_message": "Hidrataci√≥n sostenible y con estilo.",
            "content_types": ["post carrusel", "reel", "story"],
            "instructions": "Genera un plan de 3 ideas de contenido para Instagram, una por cada tipo de contenido solicitado. Incluye un t√≠tulo y una descripci√≥n breve para cada una."
        }
    }
}

print("‚úÖ Agente_Planificador (Emisor) crea el contexto MCP.")
pprint(mcp_context)
print("-" * 50)

# 3. Simulaci√≥n del Agente Receptor con LangChain
# Extraemos la informaci√≥n relevante del contexto para el prompt.
goal = mcp_context['context']['payload']['campaign_goal']
product = mcp_context['context']['payload']['product_name']
audience = mcp_context['context']['payload']['target_audience']
message = mcp_context['context']['payload']['key_message']
content_types = ", ".join(mcp_context['context']['payload']['content_types'])
instructions = mcp_context['context']['payload']['instructions']

# Definimos la plantilla del prompt para el Agente Receptor
prompt_template = """
Eres un especialista en marketing digital. Tu tarea es generar ideas de contenido para una campa√±a de redes sociales.
Basado en la siguiente informaci√≥n de la campa√±a:
- Objetivo: {goal}
- Producto: {product}
- Audiencia objetivo: {audience}
- Mensaje clave: {message}

{instructions}
Los tipos de contenido solicitados son: {content_types}

Formato de respuesta:
T√≠tulo de la Idea 1:
Descripci√≥n:
---
T√≠tulo de la Idea 2:
Descripci√≥n:
---
T√≠tulo de la Idea 3:
Descripci√≥n:
---
"""
prompt = PromptTemplate(template=prompt_template, input_variables=["goal", "product", "audience", "message", "instructions", "content_types"])

# Creamos la cadena (Chain) que conectar√° el prompt con el LLM
chain = LLMChain(llm=chat, prompt=prompt)

# Ejecutamos la cadena con la informaci√≥n extra√≠da del contexto MCP
response = chain.invoke(
    {
        "goal": goal,
        "product": product,
        "audience": audience,
        "message": message,
        "instructions": instructions,
        "content_types": content_types
    }
)

# 4. Impresi√≥n de la respuesta del Agente Receptor
print("üß† Agente_Creativo (Receptor) procesa el contexto y genera el plan de marketing:")
print(response['text'])
